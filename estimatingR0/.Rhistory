# and generates a new .csv file with the data from all epidemics
# assumes the variable 'data_file' contains the data file to use
##
## set wd etc
##
# output folder to create
output_dir        <- "outbreaks"
# columes that indicate an outbreak
outbreak_col      <- "Outbrk"
outbreak_code_col <- "OutbreakCode"
# column for report date
date_col          <- "reportdate"
date_format       <- "%d-%B-%y"
# output folder to create
output_dir        <- "outbreaks"
# survey weeks start on a saturday, so just find the previous saturday
surv_week_start <- function(date)
{
# 1. Find the previous saturday
prev_sat <- date
while (weekdays(prev_sat) != "Saturday")
prev_sat <- prev_sat - 1;
return(as.character(prev_sat))
}
surv_date <- function(date)
{
# Find the month
return(format.Date(date, "%y-%m-%d"))
}
# read in data
all <- read.csv("EbolaData.csv")
notification_dates <- as.Date(all[,date_col], format=date_format)
notification_weeks <- sapply(notification_dates, surv_week_start)
notification_date <- sapply(notification_weeks, surv_date)
# now the total incidence through time, with outbreak no's as well
allt<-cbind(as.Date(notification_weeks),all)
epis<-aggregate( cbind(New.Cases) ~ as.Date(notification_weeks) + Outbrk,
data = allt , FUN=sum)
head(epis)
colnames(epis)<-c("Week","Outbreak","Cases")
plot(epis$Week,epis$Cases)
barplot(epis$Cases,cex.names=0.8)
#ast<-as.numeric(epis$Week)
#epis<-cbind(ast,epis)
rows <- notification_weeks > "2000-10-14"
weeks_2000 <- notification_weeks[rows]
#outbreak_col      <- "Outbreak"
#outbreaks_2000 <- epis[rows,outbreak_col]
ob_range <- range(as.Date(weeks_2000))
ob_weeks <- matrix(0, length(unique(epis$Outbreak)), diff(ob_range)/7+1)
colnames(ob_weeks) <- as.character(seq(ob_range[1], ob_range[2], by=7))
rownames(ob_weeks) <- sort(unique(epis$Outbreak))
library(reshape)
library(reshape2)
library(plyr)
# JM's working code
#popn$NZDep <- as.numeric(popn$NZDep)
#popn$merge <- paste(popn$NZDep, popn$Age, popn$Ethnicity)
#testtable$merge <- paste(testtable$NZDep, testtable$Age, testtable$Ethnicity)
#testtable <- testtable[testtable$Ethnicity!="None",]
#popn$cases <- 0
#cases <- matrix(0, length(popn$merge),1)
#rownames(cases) <- popn$merge
#cases[testtable$merge,] <- testtable$Cases
#popn$cases <- cases
allwks<-as.Date(colnames(ob_weeks))
allwks<-as.data.frame(allwks)
#allwks$cases <- 0
#allwks$Outbreaks <- NA
colnames(allwks)<-c("Week")
m1<-merge(allwks,epis,by= c("Week"),all=T,incomparables = NA)
plot(m1)
barplot(m1$Cases, col="black", border=NA, space=0, xaxt="n", ylim=c(0,max(m1$Cases,na.rm=T)), ylab="Cases per week")
# figure out years...
years <- as.numeric((as.Date(paste(2000:2015, "-01-01", sep="")) - ob_range[1]) / 7)
axis(1, at=years, labels=rep("", length(years)), line=0.5)
mtext(2000:2014, side=1, at = years[-length(years)] + diff(years)/2, line=1.2,cex=0.8)
library(ggplot2)
f=ggplot(m1, aes(Week, Cases))
(f1=f+geom_line(aes(group=Outbreak, color=factor(Outbreak)))+scale_color_discrete(guide="none"))
## fill minor gaps..
for (i in 2:length(m1$Cases)){
ifelse(#(
m1$Cases[i-1]>0 #& m1$Cases[i+1]>0)
,m1$Cases[i]<-0,m1$Cases[i]<-m1$Cases[i])
}
for (i in 2:length(m1$Cases)){
ifelse(#(
m1$Cases[i+1]>0 #& m1$Cases[i+1]>0)
,m1$Cases[i]<-0,m1$Cases[i]<-m1$Cases[i])
}
for (i in 2:length(m1$Outbreak)){
ifelse(#(
m1$Cases[i]==0 && m1$Outbreak[i]==NA
,m1$Outbreak[i]<-m1$Outbreak[i-1],m1$Outbreak[i]<-m1$Outbreak[i])
}
for (i in 2:length(m1$Outbreak)){
ifelse(m1$Cases[i]==0 & m1$Outbreak[i]==NA
,m1$Outbreak[i]<-m1$Outbreak[i+1],m1$Outbreak[i]<-m1$Outbreak[i])
}
f=ggplot(m1, aes(Week, Cases))
(f1=f+geom_line(aes(group=Outbreak, color=factor(Outbreak)))+scale_color_discrete(guide="none"))
(max(!is.na(m1$Cases)))
summary(m1)
### m1<-m1[-c(361),]
m1 <- m1[order(m1$Outbreak),]
m1$Outbreak<-as.factor(m1$Outbreak)
m1[m1$Outbreak %in% 5,]
na.omit(m1)
names(m1)<-c("date","outbreak","incidence")
for (i in 2:length(unique(m1$outbreak))-1)
{
#f<-function(outbreak){
outbreak<-m1[m1$outbreak %in% i,]
week=length(outbreak)
outbreak_data <- data.frame(outbreak, week)
outbreak_file <- file.path(output_dir, sprintf("outbreak%02d.csv", i))
write.csv(outbreak_data, outbreak_file, row.names=F)
#f(outbreak)
}
mu    <- 12
sigma <- 3.5
sigma_logn <- sqrt(log(1 + (sigma/mu)^2))
mu_logn    <- log(mu) - log(1 + (sigma/mu)^2) / 2
# then exp(rnorm(n, mu_logn, sigma_logn)) simulates from lognormal with the given mean and sd.
# the R0 library can estimate our distribution from incidence data
require(R0)
source("estR0.R")
# generation time in weeks
genTime <- generation.time(type="lognormal", val=c(6, 3.5)/7)
# read out outbreak folder
outbreak_folder <- "outbreaks"
# read in and reorder by date
outbreak_files <- list.files(path=outbreak_folder, pattern="*.csv")
max_dates <- rep("", length(outbreak_files))
for (i in 1:length(outbreak_files))
{
incidence <- read.csv(file.path(outbreak_folder, outbreak_files[i]), stringsAsFactors=F)
max_dates[i] <- max(incidence$date)
}
outbreak_files <- outbreak_files[order(max_dates)]
# function for modifying colours to make them transparent
alpha <- function(col, a)
{
if (nchar(col) == 9)
rgb(t(col2rgb(substr(col,1,7))/255), alpha=a)
else
rgb(t(col2rgb(col)/255), alpha=a)
}
# do the separate analyses
average_R0 <- list()
cols <- rainbow(length(average_R0))
for (i in 1:length(outbreak_files))
{
ob_file <- outbreak_files[i]
incidence <- read.csv(file.path(outbreak_folder, ob_file))
# convert our incidence data to something we can use
counts <- incidence$incidence
names(counts) <- incidence$date
# if we have too long gaps in the data we'll need to strip it out
#  counts <- counts[1:51]
#  estR0<-estimate.R(counts, genTime, t=1:51, methods=c("EG", "ML", "TD", "AR", "SB"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("EG"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("ML"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("TD"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("SB"), pop.size=1300000, nsim=100)
# add dates....
estR0<-jm_estR0(counts, genTime, t=1:length(counts), end=length(counts), methods=c("TD"), nsim=1000)
months <- as.Date(as.vector(t(outer(2009:2015,1:12,function(x,y) { sprintf("%04d-%02d-01", x, y) }))))
month_lab_short <- c("J","F","M","A","M","J","J","A","S","O","N","D")
month_lab_long  <- months(as.Date(sprintf("2005-%02d-01", 1:12)), T)
month_lab <- rep(1:12,6)
years  <- as.Date(sprintf("%04d-01-01", 2009:2015))
date_range <- as.Date(as.character(incidence$date))
# plot...
plot(NULL, xlim=range(date_range), ylim=range(estR0$conf.int), ylab="R0", xaxt="n", xlab="")
polygon(c(date_range,rev(date_range)), c(estR0$conf.int[,1], rev(estR0$conf.int[,2])), col=alpha(cols[i], 0.5), border=NA)
lines(date_range, estR0$R, lwd=2, col=cols[i])
abline(h=1)
axis(1, at=months, labels=rep("",length(months)))
axis(1, at=years, labels=rep("",length(years)), tcl=-2.5, lwd.ticks=1.5)
incl_month <- months+10 >= min(date_range) & months+20 < max(date_range)
incl_year <- years >= min(date_range) & years < max(date_range)
#  if (sum(incl_month) < 10) {
#    mtext(month_lab_long[month_lab[incl_month]], side=1, at = months[incl_month] + 15, line=0.25)
#  } else {
#   mtext(month_lab_short[month_lab[incl_month]], side=1, at = months[incl_month] + 15, line=0.25)
# }
#  if (sum(incl_year))
#  {
#   mtext(format.Date(years[incl_year], "%Y"), side=1, at = years[incl_year], line=1.5, adj=-0.25)
#    mtext(as.numeric(format.Date(years[incl_year], "%Y"))-1, side=1, at = years[incl_year], line=1.5, adj=1.25)
#  }
average_R0[[length(average_R0)+1]] <- estR0$R0
}
warnings()
# plot R0 averages
my_vioplot <- function(dat, bw, border, col, at)
{
e <- density(dat, bw)
m <- 0.3/max(e$y)
incl <- e$y > max(e$y)/1000
polygon(c(at-e$y[incl]*m,rev(at+e$y[incl]*m)), c(e$x[incl], rev(e$x[incl])), col=col, border=border)
}
#pdf("averageR0.pdf", width=8, height=6)
#range_R0 <- range(sapply(average_R0, range))
#plot(NULL, xlim=c(0.5,length(average_R0)+0.5), ylim=range_R0 + diff(range_R0)*0.05*c(-1,1), ylab="Average R0", xlab="", xaxt="n", yaxs="i")
plot(NULL, xlim=c(0.5,3.5), ylim=c(0.3,1.2), ylab="Average R0", xlab="", xaxt="n", yaxs="i")
for (i in 1:length(average_R0))
my_vioplot(average_R0[[i]], bw=0.015, border=1:5, col=c(1:5), at=i)
abline(h=1, col="black")
#labels <- c("Early 2009", "Late 2009", "2010", "2011/12", "2014")
#axis(side=1, at=1:5, labels=labels)
dev.off()
##
library(vioplot)
hist(average_R0[[1]])
plot(NULL, xlim=c(-20,20), ylim=c(-10,30), ylab="Average R0", xlab="", xaxt="n", yaxs="i")
plot(NULL, xlim=c(0,1.2), ylim=c(-0.5,1.5))
for (i in 1:length(average_R0))
vioplot(average_R0[[i]],col=c(1,2,3,4,5,6,7,8,9,10), horizontal=TRUE, at=0, add=TRUE,lty=2, rectCol="blue")
abline(h=1, col="black")
mu    <- 12
sigma <- 3.5
sigma_logn <- sqrt(log(1 + (sigma/mu)^2))
mu_logn    <- log(mu) - log(1 + (sigma/mu)^2) / 2
# then exp(rnorm(n, mu_logn, sigma_logn)) simulates from lognormal with the given mean and sd.
# generation time in weeks
genTime <- generation.time(type="lognormal", val=c(6, 3.5)/7)
# read out outbreak folder
outbreak_folder <- "outbreaks"
# read in and reorder by date
outbreak_files <- list.files(path=outbreak_folder, pattern="*.csv")
max_dates <- rep("", length(outbreak_files))
for (i in 1:length(outbreak_files))
{
incidence <- read.csv(file.path(outbreak_folder, outbreak_files[i]), stringsAsFactors=F)
max_dates[i] <- max(incidence$date)
}
outbreak_files <- outbreak_files[order(max_dates)]
# function for modifying colours to make them transparent
alpha <- function(col, a)
{
if (nchar(col) == 9)
rgb(t(col2rgb(substr(col,1,7))/255), alpha=a)
else
rgb(t(col2rgb(col)/255), alpha=a)
}
# do the separate analyses
average_R0 <- list()
cols <- rainbow(length(average_R0))
for (i in 1:length(outbreak_files))
{
ob_file <- outbreak_files[i]
incidence <- read.csv(file.path(outbreak_folder, ob_file))
# convert our incidence data to something we can use
counts <- incidence$incidence
names(counts) <- incidence$date
# if we have too long gaps in the data we'll need to strip it out
#  counts <- counts[1:51]
#  estR0<-estimate.R(counts, genTime, t=1:51, methods=c("EG", "ML", "TD", "AR", "SB"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("EG"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("ML"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("TD"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("SB"), pop.size=1300000, nsim=100)
# add dates....
estR0<-jm_estR0(counts, genTime, t=1:length(counts), end=length(counts), methods=c("TD"), nsim=1000)
months <- as.Date(as.vector(t(outer(2009:2015,1:12,function(x,y) { sprintf("%04d-%02d-01", x, y) }))))
month_lab_short <- c("J","F","M","A","M","J","J","A","S","O","N","D")
month_lab_long  <- months(as.Date(sprintf("2005-%02d-01", 1:12)), T)
month_lab <- rep(1:12,6)
years  <- as.Date(sprintf("%04d-01-01", 2009:2015))
date_range <- as.Date(as.character(incidence$date))
# plot...
plot(NULL, xlim=range(date_range), ylim=range(estR0$conf.int), ylab="R0", xaxt="n", xlab="")
polygon(c(date_range,rev(date_range)), c(estR0$conf.int[,1], rev(estR0$conf.int[,2])), col=alpha(cols[i], 0.5), border=NA)
lines(date_range, estR0$R, lwd=2, col=cols[i])
abline(h=1)
axis(1, at=months, labels=rep("",length(months)))
axis(1, at=years, labels=rep("",length(years)), tcl=-2.5, lwd.ticks=1.5)
incl_month <- months+10 >= min(date_range) & months+20 < max(date_range)
incl_year <- years >= min(date_range) & years < max(date_range)
#  if (sum(incl_month) < 10) {
#    mtext(month_lab_long[month_lab[incl_month]], side=1, at = months[incl_month] + 15, line=0.25)
#  } else {
#   mtext(month_lab_short[month_lab[incl_month]], side=1, at = months[incl_month] + 15, line=0.25)
# }
#  if (sum(incl_year))
#  {
#   mtext(format.Date(years[incl_year], "%Y"), side=1, at = years[incl_year], line=1.5, adj=-0.25)
#    mtext(as.numeric(format.Date(years[incl_year], "%Y"))-1, side=1, at = years[incl_year], line=1.5, adj=1.25)
#  }
average_R0[[length(average_R0)+1]] <- estR0$R0
}
my_vioplot <- function(dat, bw, border, col, at)
{
e <- density(dat, bw)
m <- 0.3/max(e$y)
incl <- e$y > max(e$y)/1000
polygon(c(at-e$y[incl]*m,rev(at+e$y[incl]*m)), c(e$x[incl], rev(e$x[incl])), col=col, border=border)
}
class(average_R0)
length(average_R0)
summary(average_R0)
summary(average_R0[[1]])
summary(average_R0[[2]])
summary(average_R0[[3]])
summary(average_R0[[4]])
summary(average_R0[[5]])
summary(average_R0[[6]])
summary(average_R0[[7]])
summary(average_R0[[8]])
summary(average_R0[[9]])
summary(average_R0[[10]])
average_R0<-average_R0[-c(5,6,8,9,10)]
length(average_R0)
my_vioplot <- function(dat, bw, border, col, at)
{
e <- density(dat, bw)
m <- 0.3/max(e$y)
incl <- e$y > max(e$y)/1000
polygon(c(at-e$y[incl]*m,rev(at+e$y[incl]*m)), c(e$x[incl], rev(e$x[incl])), col=col, border=border)
}
#pdf("averageR0.pdf", width=8, height=6)
#range_R0 <- range(sapply(average_R0, range))
#plot(NULL, xlim=c(0.5,length(average_R0)+0.5), ylim=range_R0 + diff(range_R0)*0.05*c(-1,1), ylab="Average R0", xlab="", xaxt="n", yaxs="i")
plot(NULL, xlim=c(0.5,3.5), ylim=c(0.3,1.2), ylab="Average R0", xlab="", xaxt="n", yaxs="i")
for (i in 1:length(average_R0))
my_vioplot(average_R0[[i]], bw=0.015, border=1:5, col=c(1:5), at=i)
abline(h=1, col="black")
plot(NULL, xlim=c(0.5,3.5), ylim=c(0,2), ylab="Average R0", xlab="", xaxt="n", yaxs="i")
for (i in 1:length(average_R0))
my_vioplot(average_R0[[i]], bw=0.015, border=1:5, col=c(1:5), at=i)
plot(NULL, xlim=c(0.5,5.5), ylim=c(0,2), ylab="Average R0", xlab="", xaxt="n", yaxs="i")
for (i in 1:length(average_R0))
my_vioplot(average_R0[[i]], bw=0.015, border=1:5, col=c(1:5), at=i)
abline(h=1, col="black")
mu    <- 3
sigma <- 3.5
sigma_logn <- sqrt(log(1 + (sigma/mu)^2))
mu_logn    <- log(mu) - log(1 + (sigma/mu)^2) / 2
# generation time in weeks
genTime <- generation.time(type="lognormal", val=c(6, 3.5)/7)
# read out outbreak folder
outbreak_folder <- "outbreaks"
# read in and reorder by date
outbreak_files <- list.files(path=outbreak_folder, pattern="*.csv")
max_dates <- rep("", length(outbreak_files))
for (i in 1:length(outbreak_files))
{
incidence <- read.csv(file.path(outbreak_folder, outbreak_files[i]), stringsAsFactors=F)
max_dates[i] <- max(incidence$date)
}
outbreak_files <- outbreak_files[order(max_dates)]
# function for modifying colours to make them transparent
alpha <- function(col, a)
{
if (nchar(col) == 9)
rgb(t(col2rgb(substr(col,1,7))/255), alpha=a)
else
rgb(t(col2rgb(col)/255), alpha=a)
}
# do the separate analyses
average_R0 <- list()
cols <- rainbow(length(average_R0))
for (i in 1:length(outbreak_files))
{
ob_file <- outbreak_files[i]
incidence <- read.csv(file.path(outbreak_folder, ob_file))
# convert our incidence data to something we can use
counts <- incidence$incidence
names(counts) <- incidence$date
# if we have too long gaps in the data we'll need to strip it out
#  counts <- counts[1:51]
#  estR0<-estimate.R(counts, genTime, t=1:51, methods=c("EG", "ML", "TD", "AR", "SB"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("EG"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("ML"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("TD"), pop.size=1300000, nsim=100)
#  estR0<-estimate.R(counts, genTime, t=1:51, end=51, methods=c("SB"), pop.size=1300000, nsim=100)
# add dates....
estR0<-jm_estR0(counts, genTime, t=1:length(counts), end=length(counts), methods=c("TD"), nsim=1000)
months <- as.Date(as.vector(t(outer(2009:2015,1:12,function(x,y) { sprintf("%04d-%02d-01", x, y) }))))
month_lab_short <- c("J","F","M","A","M","J","J","A","S","O","N","D")
month_lab_long  <- months(as.Date(sprintf("2005-%02d-01", 1:12)), T)
month_lab <- rep(1:12,6)
years  <- as.Date(sprintf("%04d-01-01", 2009:2015))
date_range <- as.Date(as.character(incidence$date))
# plot...
plot(NULL, xlim=range(date_range), ylim=range(estR0$conf.int), ylab="R0", xaxt="n", xlab="")
polygon(c(date_range,rev(date_range)), c(estR0$conf.int[,1], rev(estR0$conf.int[,2])), col=alpha(cols[i], 0.5), border=NA)
lines(date_range, estR0$R, lwd=2, col=cols[i])
abline(h=1)
axis(1, at=months, labels=rep("",length(months)))
axis(1, at=years, labels=rep("",length(years)), tcl=-2.5, lwd.ticks=1.5)
incl_month <- months+10 >= min(date_range) & months+20 < max(date_range)
incl_year <- years >= min(date_range) & years < max(date_range)
#  if (sum(incl_month) < 10) {
#    mtext(month_lab_long[month_lab[incl_month]], side=1, at = months[incl_month] + 15, line=0.25)
#  } else {
#   mtext(month_lab_short[month_lab[incl_month]], side=1, at = months[incl_month] + 15, line=0.25)
# }
#  if (sum(incl_year))
#  {
#   mtext(format.Date(years[incl_year], "%Y"), side=1, at = years[incl_year], line=1.5, adj=-0.25)
#    mtext(as.numeric(format.Date(years[incl_year], "%Y"))-1, side=1, at = years[incl_year], line=1.5, adj=1.25)
#  }
average_R0[[length(average_R0)+1]] <- estR0$R0
}
summary(average_R0[[1]])
summary(average_R0[[2]])
summary(average_R0[[3]])
summary(average_R0[[4]])
summary(average_R0[[5]])
summary(average_R0[[6]])
summary(average_R0[[7]])
summary(average_R0[[8]])
summary(average_R0[[9]])
summary(average_R0[[10]])
